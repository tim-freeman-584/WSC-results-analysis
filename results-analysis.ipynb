{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018 Results Analysis\n",
    "\n",
    "This notebook contains some analysis of the results of the 2018 season. It includes all Wednesday and Friday evening races over the season but excludes mayhems, pursuit races, club champs and winter series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by defining some useful functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "column_headings = [\"HelmName\", \"Class\", \"PY\", \"SailNo\", \"Fleet\", \"Rank\", \"Elapsed\", \"Corrected\", \"Points\", \"Reg No.\", \"Reg Date\"]\n",
    "alternative_headings = [\"HelmName\", \"Class\", \"PY\", \"SailNo\", \"Fleet\", \"Rank\", \"Place\", \"Points\", \"Reg No.\", \"Reg Date\"]\n",
    "fleets = ['Superfast', 'Fast', 'Medium', 'Slow']\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "\n",
    "def scrape_race(url):\n",
    "    \"\"\"Scrape all the results for a single race.\"\"\"\n",
    "    print(url)\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "       html = response.read()\n",
    "    \n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    tables = soup.findAll('table')\n",
    "    return tables[:4]\n",
    "\n",
    "\n",
    "def get_dataframe_from(table):\n",
    "    \"\"\"Turn a table into a data frame.\"\"\"\n",
    "    table_rows = table.find_all('tr')\n",
    "    l = []\n",
    "    for tr in table_rows[1:]:\n",
    "        td = tr.find_all('td')\n",
    "        row = [tr.text for tr in td]\n",
    "        l.append(row)\n",
    "        \n",
    "    # Different column headers are used if there were no results recorded in a fleet.\n",
    "    if l and len(l[0]) == 11:        \n",
    "        df = pd.DataFrame(l, columns=column_headings)\n",
    "    else:\n",
    "        df = pd.DataFrame(l, columns=alternative_headings)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all results for all Wednesday and Friday races."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.warsashsc.org.uk/results/18wa1.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wa2.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wa3.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wa4.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wa5.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wa6.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wa7.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wa8.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wb1.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wb2.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wb3.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wb4.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wb5.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wb6.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wb7.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wb8.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wc1.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wc2.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wc3.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wc4.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wc5.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wc6.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wc7.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18wc8.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fa1.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fa2.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fa3.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fa4.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fa5.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fa6.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fa7.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fa8.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fb1.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fb2.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fb3.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fb4.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fb5.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fb6.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fb7.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fb8.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fc1.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fc2.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fc3.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fc4.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fc5.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fc6.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fc7.htm\n",
      "No racing\n",
      "https://www.warsashsc.org.uk/results/18fc8.htm\n",
      "No racing\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c56a41dee17d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mall_races\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_races_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\venv\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    223\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m                        copy=copy, sort=sort)\n\u001b[0m\u001b[0;32m    226\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\venv\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No objects to concatenate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "base_url = 'https://www.warsashsc.org.uk/results/18'\n",
    "series = ['wa', 'wb', 'wc', 'fa', 'fb', 'fc']\n",
    "\n",
    "all_races_frames = []\n",
    "race_on = []\n",
    "\n",
    "for s in series:\n",
    "    for i in range(1, 9):\n",
    "        try:\n",
    "            race = scrape_race(base_url + s + str(i) + '.htm')\n",
    "            \n",
    "            for table in race:\n",
    "                df = get_dataframe_from(table)\n",
    "                df['Day'] = s[0]\n",
    "                df['Series'] = s[1]\n",
    "                df['Race'] = i\n",
    "\n",
    "                all_races_frames.append(df)\n",
    "                \n",
    "            race_on.append(True)\n",
    "        except:\n",
    "            print('No racing')\n",
    "            race_on.append(False)\n",
    "        \n",
    "        \n",
    "            \n",
    "all_races = pd.concat(all_races_frames, sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There were a total of %i results recorded.' % len(all_races.index))\n",
    "\n",
    "print('There were a total of %i OCSs.' % (all_races['Elapsed'] == 'OCS').sum())\n",
    "\n",
    "print('There were a total of %i duties recorded.' %(all_races['Elapsed'] == 'Duty').sum())\n",
    "\n",
    "print('There were a total of %i DNFs recorded.' % (all_races['Elapsed'] == 'DNF').sum())\n",
    "\n",
    "excluding_duties = all_races[~all_races['Elapsed'].isin(['Duty'])]\n",
    "print('There were %i results posted excluding duties.' % len(excluding_duties.index))\n",
    "\n",
    "only_finishes = all_races[~all_races['Elapsed'].isin(['Duty', 'OCS', 'DNE', 'DNF', 'DSQ', 'AVG'])]\n",
    "print('There were %i finishes recorded.' % len(only_finishes.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_frequency = excluding_duties['Class'].value_counts()\n",
    "\n",
    "py_by_class = {}\n",
    "for c in excluding_duties['Class'].unique():\n",
    "    py_by_class[c] = excluding_duties.loc[excluding_duties['Class'] == c, 'PY'].iloc[0]\n",
    "\n",
    "print('%i different classes raced in 2018' % len(classes_frequency))\n",
    "print(classes_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pys = excluding_duties['PY'].astype(int).tolist()\n",
    "\n",
    "plt.hist(pys, bins=30)\n",
    "plt.xlabel('PY')\n",
    "plt.xticks(np.arange(min(pys), max(pys), 50))\n",
    "plt.title('Distribution of races completed by PY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Wednesday series total results')\n",
    "print(excluding_duties[excluding_duties['Day'] == 'w']['Series'].value_counts())\n",
    "print('Friday series total results')\n",
    "print(excluding_duties[excluding_duties['Day'] == 'f']['Series'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the numbers in each fleet in each Wednesday race.\n",
    "fleet_numbers = {}\n",
    "for fleet in fleets:\n",
    "    fleet_numbers[fleet] =[]\n",
    "\n",
    "wednesdays = excluding_duties[excluding_duties['Day'] == 'w']\n",
    "for s in ['a', 'b', 'c']:\n",
    "    wed_series = wednesdays[wednesdays['Series'] == s]\n",
    "    for r in range(1, 9):\n",
    "        race_numbers = wed_series[wed_series['Race'] == r]['Fleet'].value_counts()\n",
    "        for fleet in fleets:\n",
    "            if fleet in race_numbers:\n",
    "                fleet_numbers[fleet].append(race_numbers[fleet])\n",
    "            else:\n",
    "                fleet_numbers[fleet].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fleet in fleets:\n",
    "    # Remove cancelled races\n",
    "    frequencies = [n for i, n in enumerate(fleet_numbers[fleet]) if race_on[i]]\n",
    "                   \n",
    "    print(fleet)\n",
    "    print('Min = %i' % min(frequencies))\n",
    "    print('Max = %i' % max(frequencies))\n",
    "    print('Mean = %f' % np.mean(frequencies))\n",
    "    print('Median = %i' % np.median(frequencies))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fleet in fleets:\n",
    "    plt.plot((fleet_numbers[fleet]), label=fleet)\n",
    "plt.legend(fleets)\n",
    "plt.xlabel('Race')\n",
    "plt.ylabel('Number in Fleet')\n",
    "plt.title('Numbers in Each Fleet on Wednesdays')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr = [3600, 60, 1]\n",
    "i = 0\n",
    "lengths_by_fleet = {}\n",
    "for fleet in fleets:\n",
    "    lengths_by_fleet[fleet] =[]\n",
    "    \n",
    "wednesday_finishes = only_finishes[only_finishes['Day'] == 'w']\n",
    "for s in ['a', 'b', 'c']:\n",
    "    wed_series = wednesday_finishes[wednesday_finishes['Series'] == s]\n",
    "    for r in range(1, 9):\n",
    "        if race_on[i]:\n",
    "            results_for_race = wed_series[wed_series['Race'] == r]\n",
    "            for fleet in fleets:\n",
    "                results_for_fleet = results_for_race[results_for_race['Fleet'] == fleet]\n",
    "                for i, result in results_for_fleet.iterrows():\n",
    "                    try:\n",
    "                        time_in_s = sum([a*b for a,b in zip(ftr, map(int, result['Elapsed'].split(':')))])\n",
    "                        lengths_by_fleet[fleet].append(time_in_s)\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fleet in fleets:                  \n",
    "    print(fleet)\n",
    "    print('Min = %i' % min(lengths_by_fleet[fleet]))\n",
    "    print('Max = %i' % max(lengths_by_fleet[fleet]))\n",
    "    print('Mean = %f' % np.mean(lengths_by_fleet[fleet]))\n",
    "    print('Median = %i' % np.median(lengths_by_fleet[fleet]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lengths_by_fleet['Superfast'], bins=20)\n",
    "plt.title('Distribution of Wednesday Race Times for Superfast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lengths_by_fleet['Fast'], bins=20)\n",
    "plt.title('Distribution of Wednesday Race Times for Fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lengths_by_fleet['Medium'], bins=20)\n",
    "plt.title('Distribution of Wednesday Race Times for Medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lengths_by_fleet['Slow'], bins=20)\n",
    "plt.title('Distribution of Wednesday Race Times for Slow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sailors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluding_duties['HelmName'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2019 Fleet Proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_fleet_proposal_stats(fast, medium, slow):\n",
    "    \"\"\"Display fleet stats for a given proposal.\"\"\"\n",
    "    fleet_numbers = {}\n",
    "    for fleet in fleets:\n",
    "        fleet_numbers[fleet] =[]\n",
    "\n",
    "    wednesdays = excluding_duties[excluding_duties['Day'] == 'w']\n",
    "    for s in ['a', 'b', 'c']:\n",
    "        wed_series = wednesdays[wednesdays['Series'] == s]\n",
    "        for r in range(1, 9):\n",
    "            for fleet in fleets:\n",
    "                fleet_numbers[fleet].append(0)\n",
    "            for i, result in wed_series[wed_series['Race'] == r].iterrows():\n",
    "                py = int(result['PY'])\n",
    "                if py < fast:\n",
    "                    fleet = 'Superfast'\n",
    "                elif py < medium:\n",
    "                    fleet = 'Fast'\n",
    "                elif py < slow:\n",
    "                    fleet = 'Medium'\n",
    "                else:\n",
    "                    fleet = 'Slow'\n",
    "                fleet_numbers[fleet][-1] += 1\n",
    "                    \n",
    "    for fleet in fleets:\n",
    "        # Remove cancelled races\n",
    "        frequencies = [n for i, n in enumerate(fleet_numbers[fleet]) if race_on[i]]\n",
    "\n",
    "        print(fleet)\n",
    "        print('Min = %i' % min(frequencies))\n",
    "        print('Max = %i' % max(frequencies))\n",
    "        print('Mean = %f' % np.mean(frequencies))\n",
    "        print('Median = %i' % np.median(frequencies))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_fleet_proposal_stats(1030, 1090, 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
